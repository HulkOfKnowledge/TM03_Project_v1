{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad280ee6",
   "metadata": {},
   "source": [
    "# Train Credit Intelligence Models\n",
    "\n",
    "This notebook generates synthetic data, trains the payment-priority and spending-pattern models,\n",
    "and saves confusion matrix images. Run cells in order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac2d3c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b1bab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup imports and paths\n",
    "import sys, os\n",
    "# Add project root so `app` package is importable\n",
    "sys.path.append('..')\n",
    "from app.ml.data_generator import CreditDataGenerator\n",
    "from app.ml.models import CreditIntelligenceModels\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create folder for figures inside the notebook directory\n",
    "os.makedirs('figures', exist_ok=True)\n",
    "print('Setup complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1a231e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic data\n",
    "gen = CreditDataGenerator(seed=42)\n",
    "payment_data = gen.generate_payment_priority_data(n_scenarios=2000)  # scenarios for classifier\n",
    "pattern_data = gen.generate_spending_pattern_data(n_samples=3000)   # samples for classifier\n",
    "# Transaction-level data used for utilization predictor (regression)\n",
    "txn_data = gen.generate_transaction_data(n_users=200, n_months=6)\n",
    "\n",
    "print('Payment data shape:', payment_data.shape)\n",
    "print('Spending pattern data shape:', pattern_data.shape)\n",
    "print('Transaction data shape:', txn_data.shape)\n",
    "payment_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d25c3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d655b83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "txn_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80f39f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate models manager (use trained_models dir under app/ml)\n",
    "models = CreditIntelligenceModels(model_dir='../app/ml/trained_models')\n",
    "\n",
    "# Train payment priority model and show metrics\n",
    "pp_metrics = models.train_payment_priority_model(payment_data)\n",
    "models.save_scalers_and_encoders()\n",
    "print('Payment priority metrics:', pp_metrics)\n",
    "\n",
    "# Train spending pattern model and show metrics\n",
    "sp_metrics = models.train_spending_pattern_model(pattern_data)\n",
    "models.save_scalers_and_encoders()\n",
    "print('Spending pattern metrics:', sp_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a984cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate classifiers and the utilization regressor; add extra charts\n",
    "sns.set(style='whitegrid')\n",
    "\n",
    "# --- Payment Priority evaluation ---\n",
    "features_pp = ['balance','credit_limit','utilization','interest_rate','minimum_payment','days_until_due','available_funds','total_owed']\n",
    "X_pp = payment_data[features_pp]\n",
    "y_pp = payment_data['priority']\n",
    "scaler_pp = models.scalers.get('payment_priority', StandardScaler().fit(X_pp))\n",
    "X_pp_scaled = scaler_pp.transform(X_pp)\n",
    "X_train_pp, X_test_pp, y_train_pp, y_test_pp = train_test_split(X_pp_scaled, y_pp, test_size=0.2, random_state=42)\n",
    "y_pred_pp = models.payment_priority_model.predict(X_test_pp)\n",
    "acc_pp = accuracy_score(y_test_pp, y_pred_pp)\n",
    "cm_pp = confusion_matrix(y_test_pp, y_pred_pp)\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.heatmap(cm_pp, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title(f'Payment Priority Confusion Matrix (acc={acc_pp:.3f})')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/payment_priority_confusion.png', dpi=150)\n",
    "plt.show()\n",
    "print('\\nClassification report for Payment Priority:')\n",
    "print(classification_report(y_test_pp, y_pred_pp))\n",
    "\n",
    "# Feature importances for payment priority\n",
    "try:\n",
    "    importances_pp = models.payment_priority_model.feature_importances_\n",
    "    plt.figure(figsize=(8,3))\n",
    "    sns.barplot(x=importances_pp, y=features_pp)\n",
    "    plt.title('Payment Priority Feature Importances')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('figures/payment_priority_feature_importances.png', dpi=150)\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print('Could not plot payment priority importances:', e)\n",
    "\n",
    "# --- Spending Pattern evaluation ---\n",
    "features_sp = ['credit_limit','monthly_spending','utilization','transaction_frequency','avg_transaction_amount','groceries_pct','dining_pct','shopping_pct']\n",
    "X_sp = pattern_data[features_sp]\n",
    "y_sp = pattern_data['spending_pattern']\n",
    "encoder_sp = models.encoders.get('spending_pattern', LabelEncoder().fit(y_sp))\n",
    "y_sp_enc = encoder_sp.transform(y_sp)\n",
    "scaler_sp = models.scalers.get('spending_pattern', StandardScaler().fit(X_sp))\n",
    "X_sp_scaled = scaler_sp.transform(X_sp)\n",
    "X_train_sp, X_test_sp, y_train_sp, y_test_sp = train_test_split(X_sp_scaled, y_sp_enc, test_size=0.2, random_state=42)\n",
    "y_pred_sp = models.spending_pattern_model.predict(X_test_sp)\n",
    "acc_sp = accuracy_score(y_test_sp, y_pred_sp)\n",
    "cm_sp = confusion_matrix(y_test_sp, y_pred_sp)\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.heatmap(cm_sp, annot=True, fmt='d', cmap='Greens')\n",
    "plt.title(f'Spending Pattern Confusion Matrix (acc={acc_sp:.3f})')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/spending_pattern_confusion.png', dpi=150)\n",
    "plt.show()\n",
    "print('\\nClassification report for Spending Pattern:')\n",
    "print(classification_report(y_test_sp, y_pred_sp, target_names=encoder_sp.classes_))\n",
    "\n",
    "# Feature importances for spending pattern\n",
    "try:\n",
    "    importances_sp = models.spending_pattern_model.feature_importances_\n",
    "    plt.figure(figsize=(8,3))\n",
    "    sns.barplot(x=importances_sp, y=features_sp)\n",
    "    plt.title('Spending Pattern Feature Importances')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('figures/spending_pattern_feature_importances.png', dpi=150)\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print('Could not plot spending pattern importances:', e)\n",
    "\n",
    "# --- Utilization predictor (regression) ---\n",
    "# Train using transaction-level data and show regression diagnostics\n",
    "print('Training utilization predictor (may take a moment)...')\n",
    "up_metrics = models.train_utilization_predictor(txn_data)\n",
    "models.save_scalers_and_encoders()\n",
    "print('Utilization predictor metrics:', up_metrics)\n",
    "\n",
    "# Recreate monthly aggregated dataset (same steps as training function)\n",
    "df = txn_data.copy()\n",
    "df['month'] = pd.to_datetime(df['transaction_date']).dt.to_period('M')\n",
    "monthly = df.groupby(['user_id', 'card_id', 'month']).agg({\n",
    "    'amount': 'sum',\n",
    "    'transaction_date': 'count',\n",
    "    'utilization_at_transaction': 'last',\n",
    "    'credit_limit': 'first'\n",
    "}).reset_index()\n",
    "monthly.columns = ['user_id','card_id','month','monthly_spending','transaction_count','utilization','credit_limit']\n",
    "monthly = monthly.sort_values(['user_id','card_id','month'])\n",
    "monthly['next_utilization'] = monthly.groupby(['user_id','card_id'])['utilization'].shift(-1)\n",
    "monthly['prev_utilization'] = monthly.groupby(['user_id','card_id'])['utilization'].shift(1)\n",
    "monthly['spending_trend'] = monthly.groupby(['user_id','card_id'])['monthly_spending'].pct_change()\n",
    "monthly = monthly.dropna(subset=['next_utilization'])\n",
    "monthly['spending_trend'] = monthly['spending_trend'].fillna(0)\n",
    "features_up = ['utilization','monthly_spending','transaction_count','credit_limit','spending_trend']\n",
    "X_up = monthly[features_up]\n",
    "y_up = monthly['next_utilization']\n",
    "scaler_up = models.scalers.get('utilization_predictor', StandardScaler().fit(X_up))\n",
    "X_up_scaled = scaler_up.transform(X_up)\n",
    "X_train_up, X_test_up, y_train_up, y_test_up = train_test_split(X_up_scaled, y_up, test_size=0.2, random_state=42)\n",
    "y_pred_up = models.utilization_predictor.predict(X_test_up)\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "r2 = r2_score(y_test_up, y_pred_up)\n",
    "mae = mean_absolute_error(y_test_up, y_pred_up)\n",
    "mse = mean_squared_error(y_test_up, y_pred_up)\n",
    "print(f'Utilization predictor R2: {r2:.3f}, MAE: {mae:.3f}, MSE: {mse:.3f}')\n",
    "\n",
    "# Scatter plot: true vs predicted\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.scatter(y_test_up, y_pred_up, alpha=0.5)\n",
    "plt.plot([0,100],[0,100], '--', color='red')\n",
    "plt.xlabel('True Next Utilization (%)')\n",
    "plt.ylabel('Predicted Next Utilization (%)')\n",
    "plt.title('Utilization: True vs Predicted')\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/utilization_true_vs_pred.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "# Residuals histogram\n",
    "residuals = y_test_up - y_pred_up\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.histplot(residuals, bins=40, kde=True)\n",
    "plt.title('Utilization Prediction Residuals')\n",
    "plt.xlabel('Residual (True - Pred)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/utilization_residuals.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "# Feature importances for utilization predictor (regressor)\n",
    "try:\n",
    "    importances_up = models.utilization_predictor.feature_importances_\n",
    "    plt.figure(figsize=(8,3))\n",
    "    sns.barplot(x=importances_up, y=features_up)\n",
    "    plt.title('Utilization Predictor Feature Importances')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('figures/utilization_feature_importances.png', dpi=150)\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print('Could not plot utilization importances:', e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9035f1",
   "metadata": {},
   "source": [
    "How to use:\n",
    "\n",
    "- Open this notebook from `credit-intelligence-service/notebooks/train_models.ipynb`.\n",
    "- Run all cells. Figures are saved under `credit-intelligence-service/notebooks/figures/`.\n",
    "- Use the saved PNG files for screenshots in your appendix."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
